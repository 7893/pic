import { Env } from '../index';
import { analyzeImage, generateEmbedding } from './ai';
import { recordNeuronUsage, NEURON_COSTS } from './quota';
import { buildEmbeddingText } from '../utils/embedding';

/**
 * Picks a batch of old images (Llama 3.2) and upgrades them to Llama 4
 * using the remaining free Neuron quota.
 */
export async function runSelfEvolution(env: Env, remainingNeurons: number) {
  // 1. Calculate how many images we can afford to refresh
  const costPerImage = NEURON_COSTS.VISION_LLAMA_4 + NEURON_COSTS.EMBEDDING_GEMMA;
  const batchSize = Math.floor(remainingNeurons / costPerImage);

  if (batchSize <= 0) {
    console.log('üìâ No neuron budget left for evolution today.');
    return;
  }

  console.log(`üß¨ Self-Evolution: Attempting to refresh ${batchSize} images...`);

  // 2. Query D1 for old version images
  const { results } = await env.DB.prepare(
    "SELECT * FROM images WHERE ai_model = 'llama-3.2' ORDER BY created_at DESC LIMIT ?",
  )
    .bind(batchSize)
    .all<{ id: string; meta_json: string }>();

  if (results.length === 0) {
    console.log('‚ú® All images are already on the flagship model.');
    return;
  }

  // 3. Process each image (Sequential to stay within Worker memory limits)
  for (const img of results) {
    try {
      console.log(`üîÑ Refreshing image: ${img.id}`);

      const object = await env.R2.get(`display/${img.id}.jpg`);
      if (!object) continue;

      const analysis = await analyzeImage(env.AI, object.body);
      const meta = JSON.parse(img.meta_json || '{}');
      const vector = await generateEmbedding(env.AI, buildEmbeddingText(analysis.caption, analysis.tags, meta));

      // 4. Update D1 with flagship data
      await env.DB.prepare(
        `UPDATE images SET 
          ai_caption = ?, 
          ai_tags = ?, 
          ai_embedding = ?, 
          ai_model = ?, 
          ai_quality_score = ?, 
          entities_json = ? 
         WHERE id = ?`,
      )
        .bind(
          analysis.caption,
          JSON.stringify(analysis.tags),
          JSON.stringify(vector),
          'llama-4-scout',
          analysis.quality,
          JSON.stringify(analysis.entities),
          img.id,
        )
        .run();

      // 5. Deduct quota
      await recordNeuronUsage(env, costPerImage);
    } catch (error) {
      console.error(`‚ùå Evolution failed for ${img.id}:`, error);
    }
  }

  console.log(`‚úÖ Evolution batch completed.`);
}
