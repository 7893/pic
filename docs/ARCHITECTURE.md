# Lens 系统架构与分布式算法全书 (01-ARCHITECTURE)

Lens 并非一个简单的 API 封装，而是一套运行在 Cloudflare 边缘计算栈（Edge Stack）之上的、具备高度自愈与进化能力的**视觉语义对齐引擎**。本系统设计的初衷，是在极度受限的边缘环境（内存、CPU时间片、API配额）中，构建出一个具备“艺术直觉”且运营成本近乎为零的海量图片索引库。

---

## 1. 宏观架构：双管道解耦与事件驱动逻辑

Lens 的系统设计遵循 **“生产与消费物理隔离”** 的原则。系统被逻辑划分为两条独立的动态流水线，它们共用底层的存储矩阵（D1, R2, Vectorize），但在算力和触发机制上完全解耦。

### 1.1 同步搜索管道 (The Search Pipeline)

搜索管道的目标是**亚秒级响应**与**语义精准度**。当一个请求进入 API Worker 时，系统会经历以下“五阶段过滤”：

1.  **L1 HTTP 缓存层**：利用 `caches.default` 进行 URL 签名匹配。对于 10 分钟内的重复查询，系统直接在边缘数据中心返回响应，延迟低于 10ms。
2.  **L2 语义缓存层 (KV)**：检查 `semantic:cache` 命名空间。这里存储了由 Llama 4 Scout 扩展后的深度视觉词汇。由于大模型查询扩展可能需要 1-3 秒，KV 缓存的存在使得热门搜索能瞬间获得高质量的扩展词。
3.  **认知扩展 (Cognitive Expansion)**：如果缓存未命中，调用 **Llama 3.2 3B**（TEXT_FAST 选型以平衡速度）。将“关键词”转化为“视觉场景描述”，实现从字面匹配到意境感知的升维。
4.  **向量初筛与动态截断**：利用 **BGE-M3** 生成 1024 维向量，在 **Vectorize** 中进行余弦相似度检索。系统随后执行 **“断崖式检测算法”**，动态过滤掉相关度骤降的干扰项。
5.  **跨注意力精排 (Reranking)**：将剩余的前 20 张图片 Caption 丢给专用的 **BGE Reranker Base** 模块。相比简单的向量距离，Reranker 通过深度对比搜索词与描述的语义匹配度，给出最符合人类直觉的排序。

### 1.2 异步采集与进化管道 (The Ingestion & Evolution Pipeline)

这是系统的“智力工厂”，负责数据的持续摄取和存量数据的自动升级。

- **线性对撞抓取 (Linear Ingestion)**：基于每 15 分钟一次的定时脉冲，系统会动态探测 Unsplash 的最新动态。
- **分布式状态机 (Workflows)**：系统将一张图片的生命周期（下载 -> 分析 -> 打分 -> 实体识别 -> 向量化 -> 存储）拆解为 10 个原子 Step。每一个 Step 都在持久化存储中保存状态，确保了即使在云端发生网络抖动或 AI 模型负载高峰时，任务也能通过指数退避机制实现最终入库。

---

## 2. 核心算法专题：线性对撞采集模型 (Linear Boundary Ingestion)

这是 Lens 能够在 Unsplash API 每小时仅 50 次请求的极低配额下，实现产出最大化的核心算法。其数学逻辑基于**“边界探测与熔断机制”**。

### 2.1 算法的三重防护逻辑

1.  **赞助图物理隔离 (Ad-Filter)**：代码识别并强制剔除 `sponsorship !== null` 的干扰项。赞助图由于其置顶属性会破坏时间轴的连续性，通过物理过滤，我们保证了探测边界的纯净。
2.  **正向“对撞”探测 (Forward Collision)**：系统从 Page 1 开始向历史回溯。只要探测到当前页存在 D1 数据库已记录的 ID，即判定为“撞墙”。此时系统会立即停止翻页，将节省的 API 额度全部转入历史挖掘或进化。
3.  **事务化打桩 (Transactional Anchoring)**：不同于传统采集器“先改标记再干活”，Lens 只有在确认新图成功入队后，才会推高 `last_seen_id` 标记。这一细节彻底根治了在并发环境下可能出现的“数据黑洞”。

---

## 3. 全链路可观测性：分布式追踪机制 (Tracing & Observability)

为了在茫茫日志中定位故障，Lens 引入了 **Trace-ID 贯穿协议**。

### 3.1 追踪指纹的生成与传播

每一个进入系统的业务事件都会被赋予一个唯一的追踪指纹：

- `SEARCH-xxxx`：追踪单个用户搜索请求的每一个节点消耗。
- `CRON-xxxx`：追踪每一个 15 分钟抓取周期的 API 配额消耗。
- `WF-photoId-xxxx`：追踪特定图片在 Workflow 状态机中的每一个 Step 状态。

### 3.2 故障定位实战

当一张图片在 Llama 4 分析环节由于 Zod 契约校验失败时，开发者只需在日志控制台搜索 `WF-{photoId}`，即可清晰看到：该图片在 R2 存储时成功，但在 AI 解析时输出了非标准的 JSON 结构，从而触发了系统的优雅降级。

---

## 4. AI 运营经济学：UTC 23:00 爆发与财务隔离

Lens 实现了一套基于“实付金额”的闭环反馈系统，其核心哲学是：**利用免费配额的空隙实现资产重塑。**

### 4.1 财务隔离架构 (Financial Isolation)

系统通过 GraphQL API 实时探测官方账单。最牛逼的设计在于：系统会自动剔除用户搜索产生的 Reranker 费用，仅统计 **Llama 4 Scout**（旗舰分析模型）的开销。
这意味着：**用户的频繁搜索绝不会导致系统的自动进化停摆。** 它们拥有独立的财务生命线。

### 4.2 23:00 余额压榨策略

在每日配额重置前的最后一个小时（UTC 23:00），系统会发起“终极清算”：

1.  **余额探测**：`余额 = 每日限额($0.15) - 今日系统已花`。
2.  **动态派单**：根据余额算出可刷新的老图张数，批量推入任务队列。
3.  **原地洗数**：系统利用这笔“最后的一万个免费神经元”，将老旧的 3.2 版本数据洗成 4.0 旗舰版。

---

## 5. 模型分层选型与业务角色

系统拒绝使用单一巨型模型，而是采用“各司其职”的专家模式：

| 业务环节       | 模型名称            | 核心角色描述                                                              |
| :------------- | :------------------ | :------------------------------------------------------------------------ |
| **视觉理解**   | `Llama 4 Scout 17B` | **首席策展人**。负责深度语义解构、审美打分与地标实体提取。                |
| **查询扩展**   | `Llama 3.2 3B`      | **极速翻译官**。负责在 200ms 内完成用户的自然语言联想与多语言转化。       |
| **相关性精排** | `BGE Reranker Base` | **逻辑审计员**。利用 Cross-attention 机制在结果返回前进行最终的真伪鉴别。 |
| **向量化基座** | `BGE-M3 (1024d)`    | **空间坐标系**。支持 100 多种语言的密集特征映射，是检索的物理基础。       |

---

## 6. Queue + Workflow 高并发批处理架构

Evolution 采用生产者-消费者模式，实现高吞吐量的批量处理：

### 6.1 架构设计

```
┌─────────────────┐        ┌─────────────────┐        ┌─────────────────┐
│      Cron       │        │      Queue      │        │    Workflow     │
│    (生产者)     │        │                 │        │    (消费者)     │
└────────┬────────┘        └────────┬────────┘        └────────┬────────┘
         │                          │                          │
         │ 1. 查询待升级图片 ID     │                          │
         │ 2. 每100条打包           │                          │
         │                          │                          │
         │ ────sendBatch──────────▶ │                          │
         │                          │                          │
         │                          │ ┌─ Consumer 1 ─▶ WF ─────┤
         │                          │ ├─ Consumer 2 ─▶ WF ─────┤
         │                          │ ├─ Consumer 3 ─▶ WF ─────┤
         │                          │ ├─ Consumer 4 ─▶ WF ─────┤
         │                          │ └─ Consumer 5 ─▶ WF ─────┤
         │                          │   (5并发×5消息=25任务)   │
         ▼                          ▼                          ▼
```

### 6.2 并发配置 (wrangler.toml)

| 参数                | 值  | 含义                              |
| ------------------- | --- | --------------------------------- |
| `max_batch_size`    | 5   | 每个 Consumer 每批最多取 5 条消息 |
| `max_batch_timeout` | 30  | 最多等待 30 秒凑批                |
| `max_concurrency`   | 5   | 最多 5 个 Queue Consumer 并发运行 |

### 6.3 实际性能

- **并发能力**：5 Consumer × 5 消息 = 最多 25 个 Workflow 同时运行
- **单图处理时间**：~3 秒（AI 分析 + Embedding + D1 写入）
- **吞吐量**：~500 张/分钟
- **实测案例**：6,319 张图在 ~12 分钟内全部升级完成

### 6.4 为什么用 Queue + Workflow 而不是同步处理？

之前的同步方案在 Cron 中直接调用 AI，存在致命问题：

1. **Cron 30 秒超时**：批量处理几千张图必然超时
2. **钱花了事没办成**：AI 调用成功但 D1 写入因超时丢失
3. **无法重试**：失败的任务没有持久化，无法恢复

Queue + Workflow 方案的优势：

1. **Cron 只负责派发**：查询 ID、发送任务，几秒完成
2. **Workflow 持久化**：每个 Step 状态自动保存，失败可重试
3. **高并发**：25 个 Workflow 并行处理，吞吐量拉满
4. **成本可控**：预算用完自动停止，不会超支

---

## 7. KV 可配置的 Evolution 触发机制

Evolution（自进化）的触发时间和预算完全通过 KV 配置控制，无需修改代码或重新部署：

```json
{
  "backfill_enabled": false,
  "backfill_max_pages": 1,
  "daily_evolution_limit_usd": 1,
  "evolution_trigger_utc": "01:00"
}
```

| 配置项                      | 说明                                                            |
| --------------------------- | --------------------------------------------------------------- |
| `daily_evolution_limit_usd` | 每日 Evolution 预算（美元），设为 0 则关闭                      |
| `evolution_trigger_utc`     | 触发时间，格式 `"HH:MM"`，如 `"01:00"` = UTC 01:00 = 北京 09:00 |

**余额压榨策略**：在配置的触发时间，系统会发起"终极清算"：

1.  **余额探测**：`余额 = 每日限额 - 今日系统已花`。
2.  **动态派单**：根据余额算出可刷新的老图张数，批量推入任务队列。
3.  **原地洗数**：系统将老旧版本数据升级为最新旗舰版模型。

---

## 8. 成本精算：Evolution 实测数据

基于 248 个样本的实测分析：

| 指标         | 数值                |
| ------------ | ------------------- |
| 单图 AI 成本 | **$0.00025** (平均) |
| 单图 Tokens  | ~403 neurons        |
| 成本范围     | $0.00007 ~ $0.00026 |

**成本估算示例**：

| 场景             | 数量      | 预估成本 |
| ---------------- | --------- | -------- |
| 每日新图入库     | ~50 张    | ~$0.01   |
| 全库升级 (2万张) | 20,000 张 | ~$5.00   |
| $1 预算可刷      | ~3,800 张 | -        |

**免费配额**：Cloudflare 每天提供 10,000 免费 neurons，约可处理 25 张图，基本可忽略。
